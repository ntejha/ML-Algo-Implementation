{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d18a84",
   "metadata": {},
   "source": [
    "# Conditional Random Fields\n",
    "\n",
    "CRF's are powerful structured prediction models, commonly used in sequence labeling tasks. CRF's are used in Named Entity Recognition for NLP tasks.\n",
    "\n",
    "Basically, the problem with normal logistic or decision tree. what happens is it takes every word individually important. which can make it very hard to capture the sequences. So, we use CRF's which are a type od discriminative probablistic model that are particularly well suitated for sequence labeling.\n",
    "\n",
    "Let's take an example, We have a sequence of observations and we have to assign a sequence of labels (Like POS tags or named entity tags).\n",
    "\n",
    "For this example, we will use Kaggle Dataset : CoNLL003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94737f76",
   "metadata": {},
   "source": [
    "### Importing Libraries and Loading the data\n",
    "\n",
    "Things we need to download : \n",
    "- We can use CRF from the class sklearn-crfsuite\n",
    "- We use different variables to access the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923fa0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn_crfsuite import CRF, metrics\n",
    "import nltk\n",
    "\n",
    "DATA_DIR = '/home/ntejha/Projects/ML-Algo-Implementation/data/CoNLL003'\n",
    "TRAIN_FILE = '/home/ntejha/Projects/ML-Algo-Implementation/data/CoNLL003/train.txt'\n",
    "VALID_FILE = '/home/ntejha/Projects/ML-Algo-Implementation/data/CoNLL003/valid.txt'\n",
    "TEST_FILE = '/home/ntejha/Projects/ML-Algo-Implementation/data/CoNLL003/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcecdf1",
   "metadata": {},
   "source": [
    "### Understanding the data\n",
    "\n",
    "As the data is in text file, we have to make sure the sentences and store all the data into the all_sentences variables as list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13eca90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the detective's training manuals...\n",
      "Found 14041 training stories.\n",
      "Found 3250 validation stories.\n",
      "Found 3453 test stories.\n",
      "\n",
      "Here's how a small part of a training story looks:\n",
      "[('EU', 'NNP', 'B-NP', 'B-ORG'), ('rejects', 'VBZ', 'B-VP', 'O'), ('German', 'JJ', 'B-NP', 'B-MISC'), ('call', 'NN', 'I-NP', 'O'), ('to', 'TO', 'B-VP', 'O')]\n"
     ]
    }
   ],
   "source": [
    "def read_story_data(filepath):\n",
    "    \"\"\"\n",
    "    This function reads our special story files.\n",
    "    It breaks them into sentences. Each 'word' in a sentence\n",
    "    comes with its type (like Noun, Verb) and its 'name' tag (like B-PER for start of Person).\n",
    "    \"\"\"\n",
    "    all_sentences = []\n",
    "    current_sentence = [] \n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            \n",
    "            if line == '' or line.startswith('-DOCSTART-'):\n",
    "                if current_sentence: \n",
    "                    all_sentences.append(current_sentence) \n",
    "                    current_sentence = [] \n",
    "            else:\n",
    "                \n",
    "                parts = line.split() \n",
    "                if len(parts) == 4: \n",
    "                    \n",
    "                    current_sentence.append(tuple(parts))\n",
    "                else:\n",
    "                    print(f\"Heads up! Skipping a weird line: {line}\")\n",
    "\n",
    "    if current_sentence:\n",
    "        all_sentences.append(current_sentence)\n",
    "    return all_sentences\n",
    "\n",
    "print(\"Reading the detective's training manuals...\")\n",
    "training_stories = read_story_data(TRAIN_FILE)\n",
    "validation_stories = read_story_data(VALID_FILE)\n",
    "test_stories = read_story_data(TEST_FILE)\n",
    "\n",
    "print(f\"Found {len(training_stories)} training stories.\")\n",
    "print(f\"Found {len(validation_stories)} validation stories.\")\n",
    "print(f\"Found {len(test_stories)} test stories.\")\n",
    "\n",
    "print(\"\\nHere's how a small part of a training story looks:\")\n",
    "print(training_stories[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f02edb",
   "metadata": {},
   "source": [
    "### Giving the features to the Model\n",
    "\n",
    "We are giving clues that a model uses to make its decisions. For NER, we need to extract clues from each word in a sentence to help the model decide if that word is part of a person name, a location, an organization or nothing special."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20846742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clues_for_word(one_sentence_facts, word_position):\n",
    "    \"\"\"\n",
    "    This function creates a 'clue list' (features) for a single word.\n",
    "    It looks at the word itself, its tags (POS, Chunk), and its neighbors.\n",
    "    \"\"\"\n",
    "    word, pos_tag, chunk_tag, _ = one_sentence_facts[word_position] \n",
    "\n",
    "    clues = {\n",
    "        'always_on': 1.0, \n",
    "        'word_lowercase': word.lower(), \n",
    "        'last_3_letters': word[-3:],   \n",
    "        'last_2_letters': word[-2:],   \n",
    "        'is_all_caps': word.isupper(),  \n",
    "        'starts_with_cap': word.istitle(), \n",
    "        'is_a_number': word.isdigit(),  \n",
    "        'part_of_speech': pos_tag,       \n",
    "        'first_2_pos': pos_tag[:2],      \n",
    "        'chunk_tag': chunk_tag,          \n",
    "        'first_2_chunk': chunk_tag[:2],  \n",
    "    }\n",
    "\n",
    "    \n",
    "    if word_position > 0:\n",
    "        word_before, pos_before, chunk_before, _ = one_sentence_facts[word_position-1] \n",
    "        clues.update({ \n",
    "            '-1_word_lowercase': word_before.lower(),\n",
    "            '-1_starts_with_cap': word_before.istitle(),\n",
    "            '-1_is_all_caps': word_before.isupper(),\n",
    "            '-1_part_of_speech': pos_before,\n",
    "            '-1_first_2_pos': pos_before[:2],\n",
    "            '-1_chunk_tag': chunk_before,\n",
    "            '-1_first_2_chunk': chunk_before[:2],\n",
    "        })\n",
    "    else:\n",
    "        clues['is_start_of_sentence'] = True \n",
    "\n",
    "   \n",
    "    if word_position < len(one_sentence_facts) - 1: \n",
    "        word_after, pos_after, chunk_after, _ = one_sentence_facts[word_position+1]\n",
    "        clues.update({ \n",
    "            '+1_word_lowercase': word_after.lower(),\n",
    "            '+1_starts_with_cap': word_after.istitle(),\n",
    "            '+1_is_all_caps': word_after.isupper(),\n",
    "            '+1_part_of_speech': pos_after,\n",
    "            '+1_first_2_pos': pos_after[:2],\n",
    "            '+1_chunk_tag': chunk_after,\n",
    "            '+1_first_2_chunk': chunk_after[:2],\n",
    "        })\n",
    "    else:\n",
    "        clues['is_end_of_sentence'] = True \n",
    "\n",
    "    return clues\n",
    "\n",
    "def get_all_clues_for_sentence(sentence_data):\n",
    "    \"\"\" Converts a whole sentence into a list of clue-lists for each word. \"\"\"\n",
    "    return [get_clues_for_word(sentence_data, i) for i in range(len(sentence_data))]\n",
    "\n",
    "def get_all_answers_for_sentence(sentence_data):\n",
    "    \"\"\" Extracts only the NER tags (the answers) for each word in a sentence. \"\"\"\n",
    "    return [ner_tag for word, pos_tag, chunk_tag, ner_tag in sentence_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa5ab3",
   "metadata": {},
   "source": [
    "### Preparing for Learning \n",
    "\n",
    "This will gather everything and then process it and puts it into specific folders for our CRF needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a92be8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Organizing the clues (features) and answers (NER tags) for the detective...\n",
      "Example of clues for the first word of the first training story:\n",
      "{'always_on': 1.0, 'word_lowercase': 'eu', 'last_3_letters': 'EU', 'last_2_letters': 'EU', 'is_all_caps': True, 'starts_with_cap': False, 'is_a_number': False, 'part_of_speech': 'NNP', 'first_2_pos': 'NN', 'chunk_tag': 'B-NP', 'first_2_chunk': 'B-', 'is_start_of_sentence': True, '+1_word_lowercase': 'rejects', '+1_starts_with_cap': False, '+1_is_all_caps': False, '+1_part_of_speech': 'VBZ', '+1_first_2_pos': 'VB', '+1_chunk_tag': 'B-VP', '+1_first_2_chunk': 'B-'}\n",
      "Example of the correct answer for that word: B-ORG\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOrganizing the clues (features) and answers (NER tags) for the detective...\")\n",
    "\n",
    "X_train_clues = [get_all_clues_for_sentence(s) for s in training_stories]\n",
    "X_valid_clues = [get_all_clues_for_sentence(s) for s in validation_stories]\n",
    "X_test_clues = [get_all_clues_for_sentence(s) for s in test_stories]\n",
    "\n",
    "\n",
    "y_train_answers = [get_all_answers_for_sentence(s) for s in training_stories]\n",
    "y_valid_answers = [get_all_answers_for_sentence(s) for s in validation_stories]\n",
    "y_test_answers = [get_all_answers_for_sentence(s) for s in test_stories]\n",
    "\n",
    "print(f\"Example of clues for the first word of the first training story:\\n{X_train_clues[0][0]}\")\n",
    "print(f\"Example of the correct answer for that word: {y_train_answers[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeeee33",
   "metadata": {},
   "source": [
    "### Training the CRF\n",
    "\n",
    "It will train the CRF to study patterns nad learn better at identifying features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079496d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now, training our 'Detective Brain' (CRF Model). This takes a little time...\n",
      "Detective brain training finished successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\nNow, training our 'Detective Brain' (CRF Model). This takes a little time...\")\n",
    "my_ner_detective = CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1,  \n",
    "    c2=0.1,  \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True \n",
    ")\n",
    "\n",
    "try:\n",
    "    my_ner_detective.fit(X_train_clues, y_train_answers)\n",
    "    print(\"Detective brain training finished successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during training: {e}\")\n",
    "    print(\"This can sometimes happen with very small datasets or unusual feature sets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32190c1",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "This is just a series of test to check if they actually generalize the data very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bd264eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model's performance on the validation set...\n",
      "\n",
      "--- Detective's Report Card (Validation Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ORG      0.852     0.805     0.828      1341\n",
      "      B-MISC      0.925     0.839     0.880       922\n",
      "       B-PER      0.896     0.906     0.901      1842\n",
      "       I-PER      0.936     0.956     0.946      1307\n",
      "       B-LOC      0.915     0.878     0.896      1837\n",
      "       I-ORG      0.816     0.832     0.824       751\n",
      "      I-MISC      0.900     0.728     0.805       346\n",
      "       I-LOC      0.892     0.805     0.847       257\n",
      "\n",
      "   micro avg      0.895     0.868     0.882      8603\n",
      "   macro avg      0.892     0.844     0.866      8603\n",
      "weighted avg      0.896     0.868     0.881      8603\n",
      "\n",
      "Overall Name-Finding Score (F1-score) on Validation Set: 0.881\n",
      "\n",
      "Now for the final, fair test on the 'test' manual (it's never seen this before!)...\n",
      "\n",
      "--- Detective's Final Report Card (Test Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ORG      0.773     0.721     0.746      1661\n",
      "      B-MISC      0.817     0.752     0.783       702\n",
      "       B-PER      0.821     0.860     0.840      1617\n",
      "       I-PER      0.859     0.951     0.903      1156\n",
      "       B-LOC      0.854     0.815     0.834      1668\n",
      "       I-ORG      0.697     0.739     0.717       835\n",
      "      I-MISC      0.696     0.657     0.676       216\n",
      "       I-LOC      0.744     0.634     0.685       257\n",
      "\n",
      "   micro avg      0.805     0.801     0.803      8112\n",
      "   macro avg      0.783     0.766     0.773      8112\n",
      "weighted avg      0.804     0.801     0.802      8112\n",
      "\n",
      "Overall Name-Finding Score (F1-score) on Test Set: 0.802\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating the model's performance on the validation set...\")\n",
    "\n",
    "predictions_valid = my_ner_detective.predict(X_valid_clues)\n",
    "\n",
    "all_known_name_labels = list(my_ner_detective.classes_)\n",
    "if 'O' in all_known_name_labels:\n",
    "    all_known_name_labels.remove('O') \n",
    "\n",
    "print(\"\\n--- Detective's Report Card (Validation Set) ---\")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_true=y_valid_answers,          \n",
    "    y_pred=predictions_valid, \n",
    "    labels=all_known_name_labels,\n",
    "    digits=3                  \n",
    "))\n",
    "\n",
    "\n",
    "overall_f1_valid = metrics.flat_f1_score(\n",
    "    y_true=y_valid_answers,\n",
    "    y_pred=predictions_valid,\n",
    "    average='weighted', \n",
    "    labels=all_known_name_labels\n",
    ")\n",
    "print(f\"Overall Name-Finding Score (F1-score) on Validation Set: {overall_f1_valid:.3f}\")\n",
    "\n",
    "\n",
    "print(\"\\nNow for the final, fair test on the 'test' manual (it's never seen this before!)...\")\n",
    "predictions_test = my_ner_detective.predict(X_test_clues)\n",
    "\n",
    "print(\"\\n--- Detective's Final Report Card (Test Set) ---\")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_true=y_test_answers,\n",
    "    y_pred=predictions_test,\n",
    "    labels=all_known_name_labels,\n",
    "    digits=3\n",
    "))\n",
    "\n",
    "overall_f1_test = metrics.flat_f1_score(\n",
    "    y_true=y_test_answers,\n",
    "    y_pred=predictions_test,\n",
    "    average='weighted',\n",
    "    labels=all_known_name_labels\n",
    ")\n",
    "print(f\"Overall Name-Finding Score (F1-score) on Test Set: {overall_f1_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d99d51",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "This is basically to find the names in any new sentence we give it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec8f91f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Let's give our detective a new case! ---\n",
      "\n",
      "Original Story: \"Elon Musk visited Tokyo on July 20, 2025.\"\n",
      "Detective's Name Findings:\n",
      "  Word: 'Elon' -> Name Type: B-ORG\n",
      "  Word: 'Musk' -> Name Type: I-ORG\n",
      "  Word: 'visited' -> Name Type: O\n",
      "  Word: 'Tokyo' -> Name Type: B-LOC\n",
      "  Word: 'on' -> Name Type: O\n",
      "  Word: 'July' -> Name Type: O\n",
      "  Word: '20' -> Name Type: O\n",
      "  Word: ',' -> Name Type: O\n",
      "  Word: '2025' -> Name Type: O\n",
      "  Word: '.' -> Name Type: O\n",
      "\n",
      "--- Another case for our detective! ---\n",
      "\n",
      "Original Story: \"The United Nations will have a meeting in London next Monday.\"\n",
      "Detective's Name Findings:\n",
      "  Word: 'The' -> Name Type: B-ORG\n",
      "  Word: 'United' -> Name Type: I-ORG\n",
      "  Word: 'Nations' -> Name Type: I-ORG\n",
      "  Word: 'will' -> Name Type: O\n",
      "  Word: 'have' -> Name Type: O\n",
      "  Word: 'a' -> Name Type: O\n",
      "  Word: 'meeting' -> Name Type: O\n",
      "  Word: 'in' -> Name Type: O\n",
      "  Word: 'London' -> Name Type: B-LOC\n",
      "  Word: 'next' -> Name Type: O\n",
      "  Word: 'Monday' -> Name Type: O\n",
      "  Word: '.' -> Name Type: O\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Let's give our detective a new case! ---\")\n",
    "\n",
    "\n",
    "def prepare_new_story_sentence(raw_text_input):\n",
    "    \"\"\"\n",
    "    Takes a plain sentence and guesses its word parts (like POS and Chunk tags)\n",
    "    to prepare it for our detective.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(raw_text_input)\n",
    "\n",
    "    processed_sentence_facts = []\n",
    "    for word in words:\n",
    "        if word[0].isupper() and word.isalpha():\n",
    "            pos = 'NNP' \n",
    "        elif word.isdigit():\n",
    "            pos = 'CD'\n",
    "        elif word == '.':\n",
    "            pos = '.'\n",
    "        elif word == ',':\n",
    "            pos = ','\n",
    "        elif word in ['the', 'a', 'an']:\n",
    "            pos = 'DT' \n",
    "        elif word in ['will', 'was', 'is', 'visits', 'announced', 'hold', 'have']:\n",
    "            pos = 'VBD'\n",
    "        elif word in ['in', 'on', 'at', 'next']:\n",
    "            pos = 'IN' \n",
    "        elif word in ['today', 'month', 'week', 'Monday', 'July']: \n",
    "            pos = 'NN' \n",
    "        else:\n",
    "            pos = 'NN'\n",
    "\n",
    "        chunk = 'O'\n",
    "        dummy_ner = 'O'\n",
    "\n",
    "        processed_sentence_facts.append((word, pos, chunk, dummy_ner))\n",
    "    return processed_sentence_facts\n",
    "\n",
    "my_story_1 = \"Elon Musk visited Tokyo on July 20, 2025.\"\n",
    "processed_story_1 = prepare_new_story_sentence(my_story_1)\n",
    "clues_for_story_1 = get_all_clues_for_sentence(processed_story_1)\n",
    "\n",
    "predicted_name_tags_1 = my_ner_detective.predict([clues_for_story_1])[0] # Get the first (and only) sentence's tags\n",
    "\n",
    "print(f\"\\nOriginal Story: \\\"{my_story_1}\\\"\")\n",
    "print(\"Detective's Name Findings:\")\n",
    "for i, (word, _, _, _) in enumerate(processed_story_1):\n",
    "    print(f\"  Word: '{word}' -> Name Type: {predicted_name_tags_1[i]}\")\n",
    "\n",
    "print(\"\\n--- Another case for our detective! ---\")\n",
    "\n",
    "my_story_2 = \"The United Nations will have a meeting in London next Monday.\"\n",
    "processed_story_2 = prepare_new_story_sentence(my_story_2)\n",
    "clues_for_story_2 = get_all_clues_for_sentence(processed_story_2)\n",
    "predicted_name_tags_2 = my_ner_detective.predict([clues_for_story_2])[0]\n",
    "\n",
    "print(f\"\\nOriginal Story: \\\"{my_story_2}\\\"\")\n",
    "print(\"Detective's Name Findings:\")\n",
    "for i, (word, _, _, _) in enumerate(processed_story_2):\n",
    "    print(f\"  Word: '{word}' -> Name Type: {predicted_name_tags_2[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
